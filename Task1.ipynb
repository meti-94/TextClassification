{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSads5Y7JJ1XWvZeALvlz7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cfd3ef3d19a84a30ab757f25f248c18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb84e918ede443f388feea6c6048ea80",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c62ee2b7025a4a4996497f2285cd5b23",
              "IPY_MODEL_1327ef009abb486889dfab1577f78745",
              "IPY_MODEL_2726c97f10e241339560f51a3f34f5e9"
            ]
          }
        },
        "eb84e918ede443f388feea6c6048ea80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c62ee2b7025a4a4996497f2285cd5b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7857376cb7b948e78a5e6691aedabb08",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Training:   4%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d00a9397b1ed46e1ac9bb83ea56c3838"
          }
        },
        "1327ef009abb486889dfab1577f78745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ca69a38a1644b40b7ceb3c4863fc6e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc9f03b9380640f790c7e85aa7dbf78b"
          }
        },
        "2726c97f10e241339560f51a3f34f5e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b50af2d3b484c2f924fb0f0c206ca19",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/538 [00:27&lt;11:22,  1.32s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20a083fc4e5a4b7aa014d3ef39775484"
          }
        },
        "7857376cb7b948e78a5e6691aedabb08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d00a9397b1ed46e1ac9bb83ea56c3838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ca69a38a1644b40b7ceb3c4863fc6e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc9f03b9380640f790c7e85aa7dbf78b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b50af2d3b484c2f924fb0f0c206ca19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20a083fc4e5a4b7aa014d3ef39775484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fb97404e4c44213808c2d90a06586e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_950ef73396714458b181e1dd7d3fb143",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c8d01c01e41545ee95dcb45935b57a80",
              "IPY_MODEL_81249472a4ae4c95b85d6c5c8148d51e",
              "IPY_MODEL_2c978eee2e8c41d2bc7c1ce5402ec039"
            ]
          }
        },
        "950ef73396714458b181e1dd7d3fb143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8d01c01e41545ee95dcb45935b57a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db9be1f02ab14e62bc2ded8aaaf36511",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Testing: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eafba547000c461b9543b30a94c50daf"
          }
        },
        "81249472a4ae4c95b85d6c5c8148d51e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27681cd96dac49639c817917aa6a825f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 226,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 226,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b6a982922c347288c715924c4081280"
          }
        },
        "2c978eee2e8c41d2bc7c1ce5402ec039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_efcf62ed237e4ee597f915ccb5bc6780",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226/226 [01:12&lt;00:00,  3.10it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89641c7cec8942b0b1bf0599e9a8508c"
          }
        },
        "db9be1f02ab14e62bc2ded8aaaf36511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eafba547000c461b9543b30a94c50daf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27681cd96dac49639c817917aa6a825f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b6a982922c347288c715924c4081280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efcf62ed237e4ee597f915ccb5bc6780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89641c7cec8942b0b1bf0599e9a8508c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meti-94/TextClassification/blob/main/Task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWm-cbiDhn3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde46122-a02b-4986-ee43-703753ee2a01"
      },
      "source": [
        "!wget https://guillaumejaume.github.io/FUNSD/dataset.zip\n",
        "!unzip -q dataset \n",
        "!pip install -q transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-25 13:49:24--  https://guillaumejaume.github.io/FUNSD/dataset.zip\n",
            "Resolving guillaumejaume.github.io (guillaumejaume.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to guillaumejaume.github.io (guillaumejaume.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16838830 (16M) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>]  16.06M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-09-25 13:49:24 (133 MB/s) - ‘dataset.zip’ saved [16838830/16838830]\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 42.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 29.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 49.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LitAhAwLT0SM",
        "outputId": "42c3df6f-68e4-412b-e86f-41bb60b04161"
      },
      "source": [
        "!pip install -q pyyaml==5.1\n",
        "# workaround: install old version of pytorch since detectron2 hasn't released packages for pytorch 1.9 (issue: https://github.com/facebookresearch/detectron2/issues/3158)\n",
        "!pip install -q torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install detectron2 that matches pytorch 1.8\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install -q detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 274 kB 5.1 MB/s \n",
            "\u001b[?25h  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 763.5 MB 15 kB/s \n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 175 kB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.0+cu101 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 835 kB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 12.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 747 kB 42.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 743 kB 40.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 45.7 MB/s \n",
            "\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw-gIR4OZF0Y"
      },
      "source": [
        "!pip install -q datasets==1.9.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoTObgdQGMD5"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "from os.path import join\n",
        "from PIL import Image\n",
        "import json\n",
        "import sys\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import LayoutLMv2Processor\n",
        "from tqdm import tqdm \n",
        "import numpy as np \n",
        "import torch\n",
        "from datasets import Features, Sequence, Value, Array2D, Array3D\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import datasets\n",
        "\n",
        "\n",
        "model_checkpoint = \"microsoft/layoutlmv2-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "processor = LayoutLMv2Processor.from_pretrained(model_checkpoint, revision=\"no_ocr\")\n",
        "\n",
        "\n",
        "def read_image(image_path=None):\n",
        "  '''Reading image into PIL object for future use'''\n",
        "  image = Image.open(image_path).convert(\"RGB\")\n",
        "  return image\n",
        "\n",
        "def normalize_bbox(image, bboxes):\n",
        "    '''bboxes Normalization according to the expected input of the model'''\n",
        "    width, height = image.size\n",
        "    normalized_bboxes = []\n",
        "    for bbox in bboxes:\n",
        "      for part in bbox: \n",
        "        normalized_bboxes.append([\n",
        "                                  int(1000 * (part[0] / width)),\n",
        "                                  int(1000 * (part[1] / height)),\n",
        "                                  int(1000 * (part[2] / width)),\n",
        "                                  int(1000 * (part[3] / height)),\n",
        "                                  ])\n",
        "    return normalized_bboxes\n",
        "\n",
        "def flatten_annotations(annotation):\n",
        "  '''Reading the annotation file related to each image and extract the maximum number of complete questions (Question & Answer) from it'''\n",
        "  form = json.load(open(annotation, 'r'))['form']\n",
        "  words, bboxes, questions, answers = [], [], [], []\n",
        "  for idx, semantic_entity in enumerate(form):\n",
        "    if semantic_entity['label']==\"question\":\n",
        "      temp_question = [word['text'] for word in semantic_entity['words']]\n",
        "      links = semantic_entity['linking']\n",
        "      if len(links)==1:\n",
        "        links = links[0]\n",
        "        if links[0]==idx:\n",
        "          temp_answer = [word['text'] for word in form[links[1]]['words']]\n",
        "          questions.append(temp_question)\n",
        "          answers.append(temp_answer)\n",
        "    temp_words = [word['text'] for word in semantic_entity['words']] \n",
        "    temp_bboxes = [word['box'] for word in semantic_entity['words']]\n",
        "    words.append(temp_words)\n",
        "    bboxes.append(temp_bboxes)\n",
        "  return words, bboxes, questions, answers\n",
        "\n",
        "\n",
        "\n",
        "class FUNSDDataset(Dataset):\n",
        "  '''Wrapper class for creating datasets related to this task (transparency)'''\n",
        "  def __init__(self, data_path=None):\n",
        "    self.annotations = sorted(glob.glob(join(data_path, \"annotations/*.json\")))\n",
        "    self.images = sorted(glob.glob(join(data_path, \"images/*.png\")))\n",
        "    # self.data = []\n",
        "    image_list, question_list, word_list, bbox_list, start_list, end_list= [], [], [], [], [], []\n",
        "    for img, ann in tqdm(zip(self.images, self.annotations), total=len(self.images)):\n",
        "      image = read_image(img)\n",
        "      words, bboxes, questions, answers = flatten_annotations(ann)\n",
        "      bboxes = normalize_bbox(image, bboxes)\n",
        "      flatten_words, flatten_bboxes = [], []\n",
        "      for word, bbox in zip(words, bboxes):\n",
        "        flatten_words+=[item for item in word]\n",
        "      assert len(flatten_words)==len(bboxes)\n",
        "      \n",
        "        \n",
        "      for idx, (question, answer) in enumerate(zip(questions, answers)):\n",
        "        index = words.index(answer)\n",
        "        offset = len(tokenizer.tokenize(' '.join(question))) + 2\n",
        "        start_pos = 0\n",
        "        for _idx in range(index):\n",
        "          start_pos+=len(tokenizer.tokenize(' '.join(words[_idx])))\n",
        "        start_pos+=offset\n",
        "        end_pos=start_pos+len(tokenizer.tokenize(' '.join(words[index])))\n",
        "\n",
        "        image_list.append(image)\n",
        "        question_list.append(' '.join(question)),\n",
        "        word_list.append(flatten_words), \n",
        "        bbox_list.append(bboxes)\n",
        "        start_list.append(start_pos)\n",
        "        end_list.append(end_pos)\n",
        "    \n",
        "\n",
        "    \n",
        "    self.encoding = processor(image_list, \n",
        "                         question_list, \n",
        "                         word_list, \n",
        "                         boxes=bbox_list,\n",
        "                         padding=True,\n",
        "                         truncation=True, \n",
        "                         return_tensors=\"pt\")\n",
        "    self.encoding['start_positions'] = torch.tensor(start_list, dtype=torch.int64)\n",
        "    self.encoding['end_positions'] = torch.tensor(end_list, dtype=torch.int64)\n",
        " \n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return (\n",
        "            self.encoding['image'][idx],\n",
        "            self.encoding['input_ids'][idx],\n",
        "            self.encoding['token_type_ids'][idx],\n",
        "            self.encoding['attention_mask'][idx],\n",
        "            self.encoding['bbox'][idx],\n",
        "            self.encoding['start_positions'][idx],\n",
        "            self.encoding['end_positions'][idx],\n",
        "            \n",
        "            )\n",
        "  def __len__(self):\n",
        "    return len(self.encoding['image'])\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FciLKKsCYETH",
        "outputId": "db4eb686-cf95-4b49-89c5-0471c691bedc"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "\n",
        "train_ds = FUNSDDataset('./dataset/training_data')\n",
        "train_ds, valid_ds = random_split(train_ds, [int(len(train_ds)*85/100),\n",
        "                                            len(train_ds)-int(len(train_ds)*85/100)])\n",
        "test_ds = FUNSDDataset('./dataset/testing_data')\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=2, shuffle=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=2, shuffle=False)\n",
        "test_dl = DataLoader(test_ds, batch_size=2, shuffle=False)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/layoutlmv2-base-uncased were not used when initializing LayoutLMv2ForQuestionAnswering: ['layoutlmv2.visual.backbone.bottom_up.res4.14.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.stem.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv3.norm.num_batches_tracked']\n",
            "- This IS expected if you are initializing LayoutLMv2ForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LayoutLMv2ForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LayoutLMv2ForQuestionAnswering were not initialized from the model checkpoint at microsoft/layoutlmv2-base-uncased and are newly initialized: ['qa_outputs.bias', 'layoutlmv2.visual_segment_embedding', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|██████████| 149/149 [00:04<00:00, 35.22it/s]\n",
            "100%|██████████| 50/50 [00:01<00:00, 32.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494,
          "referenced_widgets": [
            "cfd3ef3d19a84a30ab757f25f248c18c",
            "eb84e918ede443f388feea6c6048ea80",
            "c62ee2b7025a4a4996497f2285cd5b23",
            "1327ef009abb486889dfab1577f78745",
            "2726c97f10e241339560f51a3f34f5e9",
            "7857376cb7b948e78a5e6691aedabb08",
            "d00a9397b1ed46e1ac9bb83ea56c3838",
            "3ca69a38a1644b40b7ceb3c4863fc6e3",
            "fc9f03b9380640f790c7e85aa7dbf78b",
            "8b50af2d3b484c2f924fb0f0c206ca19",
            "20a083fc4e5a4b7aa014d3ef39775484"
          ]
        },
        "id": "bWLZqXX8o2rK",
        "outputId": "953540eb-69ea-480e-d2c2-4eb734fe3d61"
      },
      "source": [
        "from transformers import AdamW\n",
        "from tqdm import notebook\n",
        "\n",
        "logging_step = 100\n",
        "validation_step = 200\n",
        "max_step = 1200\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "model.train()\n",
        "global_step = 0\n",
        "losses = []\n",
        "overfit = False\n",
        "\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "   if global_step==max_step:\n",
        "        break\n",
        "   for idx, batch in notebook.tqdm(enumerate(train_dl), total=len(train_dl), desc='Training'):\n",
        "      image, input_ids, token_type_ids, attention_mask, bbox, start_positions, end_positions = batch\n",
        "      # get the inputs;\n",
        "      input_ids = input_ids.to(device)\n",
        "      attention_mask = attention_mask.to(device)\n",
        "      token_type_ids = token_type_ids.to(device)\n",
        "      bbox = bbox.to(device)\n",
        "      image = image.to(device)\n",
        "      start_positions = start_positions.to(device)\n",
        "      end_positions = end_positions.to(device)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(\n",
        "                input_ids=input_ids, \n",
        "                attention_mask=attention_mask, \n",
        "                token_type_ids=token_type_ids,\n",
        "                bbox=bbox, \n",
        "                image=image, \n",
        "                start_positions=start_positions, \n",
        "                end_positions=end_positions\n",
        "                )\n",
        "      loss = outputs.loss\n",
        "      losses.append(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      global_step+=1\n",
        "      if global_step%logging_step==0:\n",
        "        print(f\"\\nCurrent Step Loss : {loss}\\t Total Loss Amount: {sum(losses)/len(losses)}\")\n",
        "        \n",
        "      if global_step%validation_step==0:\n",
        "        validation_losses= []\n",
        "        model.eval()\n",
        "        for batch in notebook.tqdm(valid_dl, desc=\"Validation\", total=len(valid_dl)):\n",
        "          with torch.no_grad():\n",
        "            image, input_ids, token_type_ids, attention_mask, bbox, start_positions, end_positions = batch\n",
        "            # get the inputs;\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            bbox = bbox.to(device)\n",
        "            image = image.to(device)\n",
        "            start_positions = start_positions.to(device)\n",
        "            end_positions = end_positions.to(device)\n",
        "            outputs = model(\n",
        "                        input_ids=input_ids, \n",
        "                        attention_mask=attention_mask, \n",
        "                        token_type_ids=token_type_ids,\n",
        "                        bbox=bbox, \n",
        "                        image=image, \n",
        "                        start_positions=start_positions, \n",
        "                        end_positions=end_positions\n",
        "                      )\n",
        "            loss = outputs.loss\n",
        "            validation_losses.append(loss)\n",
        "        print(f\"\\nValidation Loss : {sum(validation_losses)/len(validation_losses)}\")\n",
        "      if global_step==max_step:\n",
        "        break\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfd3ef3d19a84a30ab757f25f248c18c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training:   0%|          | 0/538 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Step Loss : 0.5195245146751404\t Total Loss Amount: 1.1888822317123413\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4d7e9867a1b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mglobal_step\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylegxbXH-jNJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "9fb97404e4c44213808c2d90a06586e8",
            "950ef73396714458b181e1dd7d3fb143",
            "c8d01c01e41545ee95dcb45935b57a80",
            "81249472a4ae4c95b85d6c5c8148d51e",
            "2c978eee2e8c41d2bc7c1ce5402ec039",
            "db9be1f02ab14e62bc2ded8aaaf36511",
            "eafba547000c461b9543b30a94c50daf",
            "27681cd96dac49639c817917aa6a825f",
            "8b6a982922c347288c715924c4081280",
            "efcf62ed237e4ee597f915ccb5bc6780",
            "89641c7cec8942b0b1bf0599e9a8508c"
          ]
        },
        "outputId": "8d7d3aa8-2a60-4a57-89e6-3f042053a2db"
      },
      "source": [
        "actual_starts = []\n",
        "actual_ends = []\n",
        "predicted_starts = []\n",
        "predicted_ends = []\n",
        "model.eval()\n",
        "for batch in notebook.tqdm(test_dl, desc=\"Testing\"):\n",
        "  with torch.no_grad():\n",
        "    image, input_ids, token_type_ids, attention_mask, bbox, start_positions, end_positions = batch\n",
        "    # get the inputs;\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "    token_type_ids = token_type_ids.to(device)\n",
        "    bbox = bbox.to(device)\n",
        "    image = image.to(device)\n",
        "    start_positions = start_positions.to(device)\n",
        "    end_positions = end_positions.to(device)\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = model(\n",
        "              input_ids=input_ids, \n",
        "              attention_mask=attention_mask, \n",
        "              token_type_ids=token_type_ids,\n",
        "              bbox=bbox, \n",
        "              image=image, \n",
        "              # start_positions=start_positions, \n",
        "              # end_positions=end_positions\n",
        "              )\n",
        "    # step 3: get start_logits and end_logits\n",
        "    start_logits = outputs.start_logits\n",
        "    end_logits = outputs.end_logits\n",
        "    \n",
        "    predicted_start_idx = torch.argmax(start_logits, dim=1).cpu().detach().numpy().tolist()\n",
        "    predicted_end_idx = torch.argmax(end_logits, dim=1).cpu().detach().numpy().tolist()\n",
        "    actual_start_idx = start_positions.cpu().detach().numpy().tolist()\n",
        "    actual_end_idx = end_positions.cpu().detach().numpy().tolist()\n",
        "    \n",
        "    predicted_starts+=predicted_start_idx\n",
        "    predicted_ends+=predicted_end_idx\n",
        "    actual_starts+=actual_start_idx\n",
        "    actual_ends+=actual_end_idx\n",
        "\n",
        "counter=0\n",
        "for idx in range(len(test_ds)):\n",
        "  if (actual_starts[idx]==predicted_starts[idx]\n",
        "      and actual_ends[idx]==predicted_ends[idx]):\n",
        "    counter+=1\n",
        "print(f'Accuracy on Span Detection: {counter/len(test_ds)}')\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fb97404e4c44213808c2d90a06586e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Testing:   0%|          | 0/226 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Span Detection: 0.49336283185840707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrkqtpHj4sVG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}