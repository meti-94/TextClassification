{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SKlearn_pipeline_digikala_political.ipynb",
      "provenance": [],
      "mount_file_id": "139XB7_IqTfElSDSWFLoTAPZoqggeGoB7",
      "authorship_tag": "ABX9TyNGlL7dVJpkfGSBWDRzZRH6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meti-94/BERT-QA/blob/main/SKlearn_pipeline_digikala_political.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU3uaYJI4jte",
        "outputId": "a0a4d183-ee40-4c4d-c6d6-f0eca83d0ba0"
      },
      "source": [
        "import pandas as pd \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "df = pd.read_excel('drive/My Drive/train.xlsx').fillna('')\r\n",
        "# print(df.head()) \r\n",
        "X = df['text'].to_list(); y = df['label'].to_list()\r\n",
        "df = pd.read_excel('drive/My Drive/taghche.xlsx').fillna('')\r\n",
        "# print(df[['comment', 'label_id']].head()) \r\n",
        "X2 = df['comment'].to_list(); y2 = df['label_id'].to_list()\r\n",
        "df = pd.read_excel('drive/MyDrive/snappfood.xlsx')\r\n",
        "# print(df[['comment', 'label_id']].head()) \r\n",
        "X3 = df['comment'].to_list(); y3 = df['label_id'].apply(lambda x:1-x).to_list()\r\n",
        "X+=X2; y+=y2\r\n",
        "X+=X3; y+=y3\r\n",
        "train_texts, valid_texts, train_labels, valid_labels = train_test_split(X, \r\n",
        "                                                                      y, \r\n",
        "                                                                      random_state=42, \r\n",
        "                                                                      stratify=y, \r\n",
        "                                                                      test_size=.1)\r\n",
        "print(len(train_labels), sum(y), len(valid_labels))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127033 71174 14115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l0oIDN35aSd",
        "outputId": "85286cda-75d7-45c9-84de-f7aca46e046e"
      },
      "source": [
        "# Author: Olivier Grisel <olivier.grisel@ensta.org>\r\n",
        "#         Peter Prettenhofer <peter.prettenhofer@gmail.com>\r\n",
        "#         Mathieu Blondel <mathieu@mblondel.org>\r\n",
        "# License: BSD 3 clause\r\n",
        "from pprint import pprint\r\n",
        "from time import time\r\n",
        "import logging\r\n",
        "\r\n",
        "from sklearn.datasets import fetch_20newsgroups\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "from sklearn.linear_model import SGDClassifier\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "\r\n",
        "print(__doc__)\r\n",
        "\r\n",
        "# Display progress logs on stdout\r\n",
        "logging.basicConfig(level=logging.INFO,\r\n",
        "                    format='%(asctime)s %(levelname)s %(message)s')\r\n",
        "\r\n",
        "\r\n",
        "# #############################################################################\r\n",
        "# Load some categories from the training set\r\n",
        "categories = [\r\n",
        "    'alt.atheism',\r\n",
        "    'talk.religion.misc',\r\n",
        "]\r\n",
        "# Uncomment the following to do the analysis on all the categories\r\n",
        "#categories = None\r\n",
        "\r\n",
        "print(\"Loading 20 newsgroups dataset for categories:\")\r\n",
        "print(categories)\r\n",
        "\r\n",
        "data = fetch_20newsgroups(subset='train', categories=categories)\r\n",
        "print(\"%d documents\" % len(data.filenames))\r\n",
        "print(\"%d categories\" % len(data.target_names))\r\n",
        "print()\r\n",
        "\r\n",
        "# #############################################################################\r\n",
        "# Define a pipeline combining a text feature extractor with a simple\r\n",
        "# classifier\r\n",
        "pipeline = Pipeline([\r\n",
        "    ('vect', CountVectorizer()),\r\n",
        "    ('tfidf', TfidfTransformer()),\r\n",
        "    ('clf', SGDClassifier()),\r\n",
        "])\r\n",
        "\r\n",
        "# uncommenting more parameters will give better exploring power but will\r\n",
        "# increase processing time in a combinatorial way\r\n",
        "parameters = {\r\n",
        "    'vect__max_df': (0.5, 0.75, 1.0),\r\n",
        "    # 'vect__max_features': (None, 5000, 10000, 50000),\r\n",
        "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\r\n",
        "    # 'tfidf__use_idf': (True, False),\r\n",
        "    # 'tfidf__norm': ('l1', 'l2'),\r\n",
        "    'clf__max_iter': (20,),\r\n",
        "    'clf__alpha': (0.00001, 0.000001),\r\n",
        "    'clf__penalty': ('l2', 'elasticnet'),\r\n",
        "    # 'clf__max_iter': (10, 50, 80),\r\n",
        "}\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # multiprocessing requires the fork to happen in a __main__ protected\r\n",
        "    # block\r\n",
        "\r\n",
        "    # find the best parameters for both the feature extraction and the\r\n",
        "    # classifier\r\n",
        "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\r\n",
        "\r\n",
        "    print(\"Performing grid search...\")\r\n",
        "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\r\n",
        "    print(\"parameters:\")\r\n",
        "    pprint(parameters)\r\n",
        "    t0 = time()\r\n",
        "    grid_search.fit(train_texts, train_labels)\r\n",
        "    print(\"done in %0.3fs\" % (time() - t0))\r\n",
        "    print()\r\n",
        "\r\n",
        "    print(\"Best score: %0.3f\" % grid_search.best_score_)\r\n",
        "    print(\"Best parameters set:\")\r\n",
        "    best_parameters = grid_search.best_estimator_.get_params()\r\n",
        "    for param_name in sorted(parameters.keys()):\r\n",
        "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n",
            "Loading 20 newsgroups dataset for categories:\n",
            "['alt.atheism', 'talk.religion.misc']\n",
            "857 documents\n",
            "2 categories\n",
            "\n",
            "Performing grid search...\n",
            "pipeline: ['vect', 'tfidf', 'clf']\n",
            "parameters:\n",
            "{'clf__alpha': (1e-05, 1e-06),\n",
            " 'clf__max_iter': (20,),\n",
            " 'clf__penalty': ('l2', 'elasticnet'),\n",
            " 'vect__max_df': (0.5, 0.75, 1.0),\n",
            " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 13.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done in 794.681s\n",
            "\n",
            "Best score: 0.851\n",
            "Best parameters set:\n",
            "\tclf__alpha: 1e-05\n",
            "\tclf__max_iter: 20\n",
            "\tclf__penalty: 'l2'\n",
            "\tvect__max_df: 1.0\n",
            "\tvect__ngram_range: (1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ-0yzOZ5_qi"
      },
      "source": [
        "df = pd.read_excel('drive/My Drive/test.xlsx').fillna('')\r\n",
        "X = df['text'].to_list(); y = df['label'].to_list()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tliX3OU8_uUh"
      },
      "source": [
        "preds = grid_search.predict(X)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ffGj4cbAGit",
        "outputId": "48539560-c581-4b29-8a46-e61f30682a8f"
      },
      "source": [
        "len(preds)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1516"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFg-5JnnAHw8",
        "outputId": "73fe06ad-c779-491e-d50d-08cfea6eb3c3"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "print(classification_report(y, preds))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.79      0.85      1196\n",
            "           1       0.49      0.73      0.59       320\n",
            "\n",
            "    accuracy                           0.78      1516\n",
            "   macro avg       0.70      0.76      0.72      1516\n",
            "weighted avg       0.83      0.78      0.80      1516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFCkz1x-ATJU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}